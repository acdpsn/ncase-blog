---
layout: base-layout.njk
title: "How To Become A Centaur"
date: 2018-02-06T20:29:35.000Z
tags:
- post
share_image: https://blog.ncase.me/content/images/2018/02/31517867887515-1.jpg
share_desc: ""
---

_The following is the first third of an article I wrote for MIT's Journal of Design & Science. [You can read the full version here!](https://jods.mitpress.mit.edu/pub/issue3-case)_

![](/content/images/2018/02/31517867887515.jpg)

Garry cringed, like someone just spit in his breakfast. Pawn to f5. Blue remained silent, like it just spit in someone else’s breakfast. Rook to e7: taking Garry’s queen. This was Game 6, but Garry had already lost his nerve when Blue beat him at the end of Game 2, and they’ve been drawing ever since. Garry made the move that would be his last. Bishop to e7: taking the rook that took his queen. Blue responded. Pawn to c4. Garry quickly recognized this was a set-up for Blue to invade with its queen — and knew there was no hope after that.

Garry Kasparov resigned, in less than 20 moves. On May 11th, 1997, IBM’s Deep Blue became the first AI to beat a human World Chess Champion.

You can now download a chess-playing AI better than Deep Blue on your laptop.

![](/content/images/2018/02/71513274782531.jpg)

The Story of AI
---------------

Here’s the story we’ve been telling ourselves about AI for decades: it’s man _versus_ machine, creators _versus_ their creation, a ball of wrinkly meat _versus_ a smooth block of silicon. Whether it’s our immediate worries about AI (machines stealing your job, self-driving cars making deadly mistakes, autonomous killer drones) or the more far-fetched concerns about AI (taking over the world and turning us all into pets and/or paperclips), it all comes from the same root fear: **the fear that AI will not share our human goals and values.** And what’s worse, we’ve told ourselves that our relationship between ourselves and our AI is like a chess game:

Zero-sum — one player’s win is another player’s loss.

Garry demanded a rematch. He accused IBM’s humans of secretly helping out Blue, and besides, this match he’d lost in 1997 was a rematch after he’d decisively beaten Deep Blue in 1996. Another rematch would only be fair.

IBM said no. They killed Blue, then packed up and went home. (RIP Deep Blue, 1989-1997.)

However, Garry couldn’t help but imagine: what if a human did work together with an AI? The next year, in 1998, Garry Kasparov held the world’s first game of “Centaur Chess”. Similar to how the mythological centaur was half-human, half-horse, these centaurs were teams that were half-human, half-AI.

But if humans are worse than AIs at chess, wouldn’t a Human+AI pair be worse than a solo AI? Wouldn’t the computer just be slowed down by the human, like Usain Bolt trying to run a three-legged race with his leg tied to a fat panda’s? In 2005, a online chess tournament, inspired by Garry’s centaurs, tried to answer this question. They invited all kinds of contestants — supercomputers, human grandmasters, mixed teams of humans and AIs — to compete for a grand prize.

Not surprisingly, a Human+AI Centaur beats the solo human. But — amazingly — **a Human+AI Centaur also beats the solo computer.**

This is because, contrary to unscientific internet IQ tests on clickbait websites, _intelligence is not a single dimension_. (The “g factor”, also known as “general intelligence”, only accounts for 30-50% of a individual’s performance on different cognitive tasks. So while it is an important dimension, it’s not the _only_ dimension.) For example, human grandmasters are good at long-term chess strategy, but poor at seeing ahead for millions of possible moves — while the reverse is true for chess-playing AIs. And because humans & AIs are strong on _different_ dimensions, _together_, as a centaur, they can beat out solo humans and computers alike.

But won’t AI eventually get better at the dimensions of intelligence _we_ excel at? Maybe. However, consider the “No Free Lunch” theorem, which comes from the field of _machine learning itself_. The theorem states that no problem-solving algorithm (or “intelligence”) can out-do random chance on all possible problems: instead, _an intelligence has to specialize_. A squirrel intelligence specializes in being a squirrel. A human intelligence specializes in being a human. And if you’ve ever had the displeasure of trying to figure out how to keep squirrels out of your bird feeders, you know that even squirrels can outsmart humans on some dimensions of intelligence. This may be a hopeful sign: even humans will continue to outsmart computers on some dimensions.

Now, not only does pairing humans with AIs solve a _technical_ problem — how to overcome the weaknesses of humans/AI with the strengths of AI/humans — it also solves that _moral_ problem: how do we make sure AIs share our human goals and values?

And it’s simple: if you can’t beat ‘em, join ‘em!

The rest of this essay will be about AI’s forgotten cousin, **IA: Intelligence Augmentation.** The old story of AI is about human brains _working against_ silicon brains. The new story of IA will be about human brains _working with_ silicon brains. As it turns out, most of the world is the opposite of a chess game:

Non-zero-sum — _both players can win_.

In the next few sections, I’ll talk about the past, present, and possible future of IA — how we humans have built tools to amplify our intellectual strengths, and overcome our intellectual weaknesses. I’ll show how humans are already working _with_ AIs in various fields, from art to engineering. And finally, I’ll give some rough ideas on how you can design a good partnership with an AI — how to become a centaur.

Together, humans and AI can go from “checkmate”, to “teammate”.

**To read the rest of this article, [check it out over at MIT's website!](https://jods.pubpub.org/pub/issue3-case#the-story-of-ia) (Don't worry, it's not paywalled or anything. Open access, yo.)**